# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19nqJ4jhuWXtwKtNZws8lelGs1I1m_uza
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np

# Завантаження та підготовка даних CIFAR-10
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Нормалізація
])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)

# Визначення автоенкодера
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        # Енкодер
        self.encoder = nn.Sequential(
            nn.Linear(3 * 32 * 32, 512),
            nn.ReLU(),
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.Linear(128, 64)  # Стиснута репрезентація
        )
        # Декодер
        self.decoder = nn.Sequential(
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 512),
            nn.ReLU(),
            nn.Linear(512, 3 * 32 * 32),
            nn.Sigmoid()  # Вивід в діапазон [0, 1]
        )

    def forward(self, x):
        x = x.view(-1, 3 * 32 * 32)  # Перетворення зображення у вектор
        x = self.encoder(x)
        x = self.decoder(x)
        x = x.view(-1, 3, 32, 32)  # Перетворення в зображення
        return x

# Ініціалізація моделі, функції втрат і оптимізатора
autoencoder = Autoencoder()
criterion = nn.MSELoss()  # Середньоквадратична похибка
optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)

# Навчання автоенкодера
epochs = 20
for epoch in range(epochs):
    running_loss = 0.0
    for inputs, _ in trainloader:  # Вхідні зображення одночасно є і ціллю
        optimizer.zero_grad()
        outputs = autoencoder(inputs)
        loss = criterion(outputs, inputs)  # Втрата між оригінальним і відновленим зображенням
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print(f"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(trainloader)}")

# Функція для візуалізації
def show_images(images, reconstructed=None, num_images=5):
    fig, axs = plt.subplots(2, num_images, figsize=(15, 5))
    for i in range(num_images):
        axs[0, i].imshow(np.transpose((images[i] + 1) / 2, (1, 2, 0)))  # Оригінал
        axs[0, i].axis('off')
        if reconstructed is not None:
            axs[1, i].imshow(np.transpose((reconstructed[i].detach().numpy() + 1) / 2, (1, 2, 0)))  # Відновлене
            axs[1, i].axis('off')
    plt.show()

# Відновлення зображень
dataiter = iter(trainloader)
images, _ = next(dataiter)
with torch.no_grad():
    reconstructed = autoencoder(images)
show_images(images, reconstructed)



# Генерація нових зображень
def generate_images(model, num_images=5):
    random_vectors = torch.randn(num_images, 64)  # Випадкові вектори у латентному просторі
    with torch.no_grad():
        generated = model.decoder(random_vectors).view(-1, 3, 32, 32)  # Прогін через декодер
    return generated

generated_images = generate_images(autoencoder, num_images=5)
show_images(generated_images)

"""........................................................................................................

"""

# Покращений автоенкодер зі згортками
class ConvAutoencoder(nn.Module):
    def __init__(self):
        super(ConvAutoencoder, self).__init__()
        # Енкодер
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # [64, 16, 16]
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # [128, 8, 8]
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # [256, 4, 4]
            nn.ReLU()
        )
        # Декодер
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # [128, 8, 8]
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # [64, 16, 16]
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),  # [3, 32, 32]
            nn.Tanh()  # Для діапазону [-1, 1]
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Ініціалізація моделі, функції втрат і оптимізатора
autoencoder = ConvAutoencoder()
criterion = nn.MSELoss()  # Середньоквадратична похибка
optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)

# Навчання автоенкодера
epochs = 5  # Збільшення кількості епох
for epoch in range(epochs):
    running_loss = 0.0
    for inputs, _ in trainloader:  # Вхідні зображення одночасно є і ціллю
        optimizer.zero_grad()
        outputs = autoencoder(inputs)
        loss = criterion(outputs, inputs)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print(f"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(trainloader)}")

# Функція для візуалізації
def show_images(images, reconstructed=None, num_images=5):
    fig, axs = plt.subplots(2, num_images, figsize=(15, 5))
    for i in range(num_images):
        axs[0, i].imshow(np.transpose((images[i] + 1) / 2, (1, 2, 0)))  # Оригінал
        axs[0, i].axis('off')
        if reconstructed is not None:
            axs[1, i].imshow(np.transpose((reconstructed[i].detach().numpy() + 1) / 2, (1, 2, 0)))  # Відновлене
            axs[1, i].axis('off')
    plt.show()

# Відновлення зображень
dataiter = iter(trainloader)
images, _ = next(dataiter)
with torch.no_grad():
    reconstructed = autoencoder(images)
show_images(images, reconstructed)

